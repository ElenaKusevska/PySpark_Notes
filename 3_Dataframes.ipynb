{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd0f063-da81-4810-a952-be024c3426e8",
   "metadata": {},
   "source": [
    "In order to use dataframes and the SQL engine in Apache Spark (SparkSQL), we need a Spark Session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cae42ee-d948-4bec-82cb-b7a9e67df0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "313893d0-e4e0-4b55-ab52-da07521a3e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edda6664-d496-45cb-b9ab-6e93408ce82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/17 02:41:32 WARN Utils: Your hostname, elena-VB resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "24/04/17 02:41:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/17 02:41:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdbae2fa-5ffd-4a4b-b7c9-d6e9b82323cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fdb17bb21d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0c40b2-576e-47dc-84f3-c11d0af8cc1e",
   "metadata": {},
   "source": [
    "## Spark Dataframes\n",
    "\n",
    "A DataFrame is two-dimensional. Columns can be of different data types. DataFrames accept many data inputs including series and other DataFrames. You can pass indexes (row labels) and columns (column labels). Indexes can be numbers, dates, or strings/tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db4eee9-35f2-4014-9b6d-19086fab169a",
   "metadata": {},
   "source": [
    "### Read dataset as Spark dataframe from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "632d3571-7af9-4305-a126-db84941b5094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dataset as Spark dataframe from json file\n",
    "df = spark.read.json('people.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f284da36-e51d-40cc-934d-c98cb222d104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age|   name|\n",
      "+---+-------+\n",
      "| 25|Michael|\n",
      "| 24|   Andy|\n",
      "| 19| Justin|\n",
      "| 26| George|\n",
      "| 30|   Jeff|\n",
      "+---+-------+\n",
      "\n",
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('age', 'bigint'), ('name', 'string')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show()\n",
    "df.head(2)\n",
    "df.printSchema()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ced880ea-eeee-408e-849c-586ce553b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dataset as Spark dataframe from csv file\n",
    "df = spark.read.option('header','true').csv('people.csv', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a27097c-c274-4372-ac01-80c31f1f308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|Michael| 25|\n",
      "|   Andy| 24|\n",
      "| Justin| 19|\n",
      "| George| 26|\n",
      "|   Jeff| 30|\n",
      "+-------+---+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'int')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show()\n",
    "df.head(2)\n",
    "df.printSchema()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aa3fe9b-1f10-47bd-9732-e0059eeb7073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|Michael|\n",
      "|   Andy|\n",
      "| Justin|\n",
      "| George|\n",
      "|   Jeff|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19c7abad-8937-4ac1-a7c8-604c5ae8b042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|Michael|\n",
      "|   Andy|\n",
      "| Justin|\n",
      "| George|\n",
      "|   Jeff|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df[\"name\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d57f85e6-a804-46f0-b263-0c77c07a4a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age|   name|\n",
      "+---+-------+\n",
      "| 25|Michael|\n",
      "| 24|   Andy|\n",
      "| 26| George|\n",
      "| 30|   Jeff|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filtering\n",
    "df.filter(df[\"age\"] > 21).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df6c5023-f1f7-4489-9849-3a26b3edf310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "| 26|    1|\n",
      "| 19|    1|\n",
      "| 25|    1|\n",
      "| 30|    1|\n",
      "| 24|    1|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aggregation of data\n",
    "df.groupBy(\"age\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc69fce-46b3-4c37-88bc-0650a4328644",
   "metadata": {},
   "source": [
    "### Add and drop a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ec4b115-895d-48bd-9926-bda34b4dd156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----------+\n",
      "|age|   name|name_length|\n",
      "+---+-------+-----------+\n",
      "| 25|Michael|          7|\n",
      "| 24|   Andy|          4|\n",
      "| 19| Justin|          6|\n",
      "| 26| George|          6|\n",
      "| 30|   Jeff|          4|\n",
      "+---+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add a column\n",
    "\n",
    "from pyspark.sql.functions import length\n",
    "\n",
    "df = df.withColumn('name_length', length(df['name']))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab378d13-e59d-49ee-aa43-09f6b70d19b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age|   name|\n",
      "+---+-------+\n",
      "| 25|Michael|\n",
      "| 24|   Andy|\n",
      "| 19| Justin|\n",
      "| 26| George|\n",
      "| 30|   Jeff|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop a column\n",
    "\n",
    "df = df.drop('name_length')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95b9b719-79ad-44fd-8843-0bb60d2725c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc747c-ff14-4a57-87ac-76575e69fb48",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67fd2d9d-8154-45c6-8eef-b32e9b6b5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = spark.read.option('header','true').csv('class_grades.csv', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eeb4417d-0997-4559-8258-bbf33d31ef52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+-------+--------+-----+\n",
      "|Prefix|Assignment|Tutorial|Midterm|TakeHome|Final|\n",
      "+------+----------+--------+-------+--------+-----+\n",
      "|     5|     57.14|   34.09|  64.38|   51.48| 52.5|\n",
      "|     8|     95.05|  105.49|   67.5|   99.07|68.33|\n",
      "|     8|      83.7|   83.17|   30.0|   63.15|48.89|\n",
      "|     7|     81.22|   96.06|  49.38|  105.93|80.56|\n",
      "|     8|     91.32|   93.64|   95.0|  107.41|73.89|\n",
      "|     7|      95.0|   92.58|  93.12|   97.78|68.06|\n",
      "|     8|     95.05|  102.99|  56.25|   99.07| 50.0|\n",
      "|     7|     72.85|   86.85|   60.0|    NULL|56.11|\n",
      "|     8|     84.26|    93.1|   47.5|   18.52|50.83|\n",
      "|     7|      90.1|   97.55|  51.25|   88.89|63.61|\n",
      "+------+----------+--------+-------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaa3bcd2-2d3a-41bc-afe2-aeb028f33cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df_missing.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15b9a097-81cb-4bf3-b11f-6aa533623fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+-------+--------+-----+\n",
      "|Prefix|Assignment|Tutorial|Midterm|TakeHome|Final|\n",
      "+------+----------+--------+-------+--------+-----+\n",
      "|     5|     57.14|   34.09|  64.38|   51.48| 52.5|\n",
      "|     8|     95.05|  105.49|   67.5|   99.07|68.33|\n",
      "|     8|      83.7|   83.17|   30.0|   63.15|48.89|\n",
      "|     7|     81.22|   96.06|  49.38|  105.93|80.56|\n",
      "|     8|     91.32|   93.64|   95.0|  107.41|73.89|\n",
      "|     7|      95.0|   92.58|  93.12|   97.78|68.06|\n",
      "|     8|     95.05|  102.99|  56.25|   99.07| 50.0|\n",
      "|     8|     84.26|    93.1|   47.5|   18.52|50.83|\n",
      "|     7|      90.1|   97.55|  51.25|   88.89|63.61|\n",
      "|     7|     80.44|    90.2|   75.0|   91.48|39.72|\n",
      "+------+----------+--------+-------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_missing.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9930e-802e-4e56-ac90-aa6ad0f554b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
